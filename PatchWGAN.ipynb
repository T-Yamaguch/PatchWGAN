{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PatchWGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/T-Yamaguch/PatchWGAN/blob/master/PatchWGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8Tzp4G4_cKs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "924215a8-db69-4af6-bc88-0ef1a4fc0f81"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JkBM0L4_c9H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Input, Concatenate, Conv2D, \\\n",
        "MaxPooling2D, Activation, ReLU, LeakyReLU, UpSampling2D, BatchNormalization, \\\n",
        "Dropout, Dense, Flatten, Add, LayerNormalization, GaussianNoise, Reshape, Lambda\n",
        "from keras.regularizers import l2\n",
        "\n",
        "class conv_block(Model):\n",
        "  def __init__(self, filter_num, kernel_size, kernel_regularizer= l2(0.001)):\n",
        "    super(conv_block, self).__init__()\n",
        "    self.conv = Conv2D(filter_num, kernel_size, padding = 'same', kernel_regularizer= kernel_regularizer)\n",
        "    self.norm = BatchNormalization(trainable=True)\n",
        "    self.act = LeakyReLU()\n",
        "    self.up = UpSampling2D((2,2))\n",
        "    self.noise = GaussianNoise(0.2)\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.conv(x)\n",
        "    x = self.norm(x)\n",
        "    x = self.act(x)\n",
        "    x = self.up(x)\n",
        "    x = self.noise(x)\n",
        "    return x\n",
        "\n",
        "class res_block(Model):\n",
        "  def __init__(self, filter_num, kernel_size, kernel_regularizer= l2(0.001)):\n",
        "    super(res_block, self).__init__()\n",
        "    self.conv1 = Conv2D(filter_num, kernel_size, padding = 'same', kernel_regularizer= kernel_regularizer)\n",
        "    self.conv2 = Conv2D(filter_num, kernel_size, padding = 'same', kernel_regularizer= kernel_regularizer)\n",
        "    self.norm1 = BatchNormalization(trainable=True)\n",
        "    self.norm2 = BatchNormalization(trainable=True)\n",
        "    self.act1 = LeakyReLU()\n",
        "    self.act2 = LeakyReLU()\n",
        "    self.add = Add()\n",
        "\n",
        "  def call(self, x):\n",
        "    y = self.conv1(x)\n",
        "    y = self.norm1(y)\n",
        "    y = self.act1(y)\n",
        "    y = self.conv2(y)\n",
        "    y = self.norm2(y)\n",
        "    y = self.act2(y)\n",
        "    x = self.add([x, y])\n",
        "    return x\n",
        "\n",
        "class disc_block(Model):\n",
        "  def __init__(self, filter_num, kernel_size, kernel_regularizer= l2(0.001)):\n",
        "    super(disc_block, self).__init__()\n",
        "    self.conv = Conv2D(filter_num, kernel_size, padding = 'same', kernel_regularizer= kernel_regularizer)\n",
        "    self.norm = BatchNormalization(trainable=True)\n",
        "    self.act = LeakyReLU()\n",
        "    self.pooling = MaxPooling2D((2,2), strides=(2,2))\n",
        "    self.drop = Dropout(0.3)\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.conv(x)\n",
        "    # x = self.norm(x) dにnorm入れないほうがいいという噂\n",
        "    x = self.act(x)\n",
        "    x = self.pooling(x)\n",
        "    x = self.drop(x)\n",
        "    return x\n",
        "\n",
        "class dense_block(Model):\n",
        "  def __init__(self, filter_num, kernel_regularizer= l2(0.001)):\n",
        "    super(dense_block, self).__init__()\n",
        "    self.dense = Dense(filter_num, kernel_regularizer= kernel_regularizer)\n",
        "    self.norm = BatchNormalization(trainable=True)\n",
        "    self.act = LeakyReLU()\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.dense(x)\n",
        "    x = self.norm(x)\n",
        "    x = self.act(x)\n",
        "    return x\n",
        "\n",
        "class dense_block_wo_norm(Model):\n",
        "  def __init__(self, filter_num, kernel_regularizer= l2(0.001)):\n",
        "    super(dense_block_wo_norm, self).__init__()\n",
        "    self.dense = Dense(filter_num, kernel_regularizer= kernel_regularizer)\n",
        "    self.act = LeakyReLU()\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.dense(x)\n",
        "    x = self.act(x)\n",
        "    return x\n",
        "\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fx2s6XE9_mkK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "84a3b977-fc22-4976-c4ec-ea0b22e6f12b"
      },
      "source": [
        "class Generator():\n",
        "  def __init__(self):\n",
        "    self.channel_num = 256\n",
        "    self.layer_num = 3\n",
        "    self.res_num = 0\n",
        "    self.latent_num = 8\n",
        "    self.inputs = Input(shape=(self.latent_num)) \n",
        "    self.kernel_size = (5, 5)\n",
        "    self.name = 'generator'\n",
        "    self.kernel_regularizer= None\n",
        "      \n",
        "  def model(self):\n",
        "    x = self.inputs\n",
        "\n",
        "    final_size = 4*4*self.channel_num\n",
        "    data_size = self.latent_num\n",
        "\n",
        "    while data_size*64 < final_size:\n",
        "      data_size *= 64\n",
        "      x = dense_block(data_size, kernel_regularizer= self.kernel_regularizer)(x)\n",
        "\n",
        "    x = dense_block(final_size, kernel_regularizer= self.kernel_regularizer)(x)\n",
        "    x = Reshape((4, 4, self.channel_num))(x)\n",
        "\n",
        "    filter_num = self.channel_num\n",
        "    \n",
        "    for n in range(self.layer_num):\n",
        "      for m in range(self.res_num):\n",
        "        x = res_block(filter_num, self.kernel_size, kernel_regularizer= self.kernel_regularizer)(x)\n",
        "      # filter_num /= 2\n",
        "      x = conv_block(filter_num, self.kernel_size, kernel_regularizer= self.kernel_regularizer)(x)\n",
        "\n",
        "    for m in range(self.res_num):\n",
        "      x = res_block(filter_num, self.kernel_size, kernel_regularizer= self.kernel_regularizer)(x)\n",
        "\n",
        "    x = Conv2D(3, self.kernel_size, padding = 'same', kernel_regularizer= self.kernel_regularizer)(x)\n",
        "    x = Activation('sigmoid')(x)\n",
        "    outputs = x\n",
        "    return Model(inputs = self.inputs, outputs = outputs, name = self.name)\n",
        "\n",
        "g = Generator()\n",
        "g.model().summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"generator\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 8)]               0         \n",
            "_________________________________________________________________\n",
            "dense_block (dense_block)    (None, 512)               6656      \n",
            "_________________________________________________________________\n",
            "dense_block_1 (dense_block)  (None, 4096)              2117632   \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv_block (conv_block)      (None, 8, 8, 256)         1639680   \n",
            "_________________________________________________________________\n",
            "conv_block_1 (conv_block)    (None, 16, 16, 256)       1639680   \n",
            "_________________________________________________________________\n",
            "conv_block_2 (conv_block)    (None, 32, 32, 256)       1639680   \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 32, 32, 3)         19203     \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 32, 32, 3)         0         \n",
            "=================================================================\n",
            "Total params: 7,062,531\n",
            "Trainable params: 7,051,779\n",
            "Non-trainable params: 10,752\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ie8PcTw_nEC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bf908e07-be4b-468e-f671-4501832f86f5"
      },
      "source": [
        "class Discriminator():\n",
        "  def __init__(self):\n",
        "    self.channel_num = 16\n",
        "    self.layer_num = 3\n",
        "    self.latent_num = 8\n",
        "    self.input_shape = (32, 32, 3)\n",
        "    self.patch_shape = (8, 8, 3)\n",
        "    self.patch_stride = 4\n",
        "    self.inputs = Input(shape=self.input_shape)\n",
        "    self.patch_inputs = Input(shape=self.patch_shape)\n",
        "    self.kernel_size = (5, 5)\n",
        "    self.name = 'discriminator'\n",
        "    self.kernel_regularizer= None\n",
        "\n",
        "  def patch_model(self):\n",
        "    x = self.patch_inputs\n",
        "\n",
        "    filter_num = self.channel_num\n",
        "    for n in range(self.layer_num):\n",
        "      x = disc_block(filter_num, self.kernel_size, kernel_regularizer= self.kernel_regularizer)(x)\n",
        "      filter_num *= 2\n",
        "\n",
        "    outputs = x\n",
        "\n",
        "    return Model(inputs = self.patch_inputs, outputs = outputs, name = 'patch_model')\n",
        "\n",
        "  def model(self):\n",
        "    x = self.inputs\n",
        "\n",
        "    h, w = self.input_shape[:-1]\n",
        "    ph, pw = self.patch_shape[:-1]\n",
        "    st = self.patch_stride\n",
        "    list_row_idx = [(i*st, i*st+ph) for i in range((h-ph)//st)]\n",
        "    list_col_idx = [(i*st, i*st+pw) for i in range((w-pw)//st)]\n",
        "\n",
        "    list_patch = []\n",
        "    for row_idx in list_row_idx:\n",
        "        for col_idx in list_col_idx:\n",
        "            x_patch = Lambda(lambda z: z[:, row_idx[0]:row_idx[1], col_idx[0]:col_idx[1], :])(x)\n",
        "            list_patch.append(x_patch)\n",
        "\n",
        "    patch_num = ((h-ph)//st)*((w-pw)//st)\n",
        "\n",
        "    patch_model = self.patch_model()\n",
        "    x = [patch_model(list_patch[i]) for i in range(patch_num)]\n",
        "\n",
        "    x = Concatenate(axis=-1)(x)\n",
        "\n",
        "\n",
        "    # filter_num = self.channel_num\n",
        "    # for n in range(self.layer_num):\n",
        "    #   x = disc_block(filter_num, self.kernel_size, kernel_regularizer= self.kernel_regularizer)(x)\n",
        "    #   filter_num *= 2\n",
        "    # x = Conv2D(filter_num, self.kernel_size, padding = 'same', kernel_regularizer= self.kernel_regularizer)(x)\n",
        "    # x = LeakyReLU()(x)\n",
        "\n",
        "    # x1 = Dense(1)(x)\n",
        "    # x1 = Activation('tanh')(x1)\n",
        "\n",
        "    # x2 = Dense(self.latent_num)(x)\n",
        "    # x2 = Activation('sigmoid')(x2)\n",
        "\n",
        "    # outputs = [x1, x2]\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    # x = dense_block_wo_norm(64, kernel_regularizer= self.kernel_regularizer)(x)\n",
        "    outputs = Dense(1)(x)\n",
        "\n",
        "    return Model(inputs = self.inputs, outputs = outputs, name = self.name)\n",
        "\n",
        "d = Discriminator()\n",
        "d.patch_model().summary()\n",
        "d.model().summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"patch_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 8, 8, 3)]         0         \n",
            "_________________________________________________________________\n",
            "disc_block (disc_block)      (None, 4, 4, 16)          1216      \n",
            "_________________________________________________________________\n",
            "disc_block_1 (disc_block)    (None, 2, 2, 32)          12832     \n",
            "_________________________________________________________________\n",
            "disc_block_2 (disc_block)    (None, 1, 1, 64)          51264     \n",
            "=================================================================\n",
            "Total params: 65,312\n",
            "Trainable params: 65,312\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"discriminator\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 8, 8, 3)      0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 8, 8, 3)      0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 8, 8, 3)      0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3 (Lambda)               (None, 8, 8, 3)      0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4 (Lambda)               (None, 8, 8, 3)      0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_5 (Lambda)               (None, 8, 8, 3)      0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_6 (Lambda)               (None, 8, 8, 3)      0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_7 (Lambda)               (None, 8, 8, 3)      0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_8 (Lambda)               (None, 8, 8, 3)      0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_9 (Lambda)               (None, 8, 8, 3)      0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_10 (Lambda)              (None, 8, 8, 3)      0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_11 (Lambda)              (None, 8, 8, 3)      0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_12 (Lambda)              (None, 8, 8, 3)      0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_13 (Lambda)              (None, 8, 8, 3)      0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_14 (Lambda)              (None, 8, 8, 3)      0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_15 (Lambda)              (None, 8, 8, 3)      0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_16 (Lambda)              (None, 8, 8, 3)      0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_17 (Lambda)              (None, 8, 8, 3)      0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_18 (Lambda)              (None, 8, 8, 3)      0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_19 (Lambda)              (None, 8, 8, 3)      0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_20 (Lambda)              (None, 8, 8, 3)      0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_21 (Lambda)              (None, 8, 8, 3)      0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_22 (Lambda)              (None, 8, 8, 3)      0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_23 (Lambda)              (None, 8, 8, 3)      0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_24 (Lambda)              (None, 8, 8, 3)      0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_25 (Lambda)              (None, 8, 8, 3)      0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_26 (Lambda)              (None, 8, 8, 3)      0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_27 (Lambda)              (None, 8, 8, 3)      0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_28 (Lambda)              (None, 8, 8, 3)      0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_29 (Lambda)              (None, 8, 8, 3)      0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_30 (Lambda)              (None, 8, 8, 3)      0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_31 (Lambda)              (None, 8, 8, 3)      0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_32 (Lambda)              (None, 8, 8, 3)      0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_33 (Lambda)              (None, 8, 8, 3)      0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_34 (Lambda)              (None, 8, 8, 3)      0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_35 (Lambda)              (None, 8, 8, 3)      0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "patch_model (Functional)        (None, 1, 1, 64)     65312       lambda[0][0]                     \n",
            "                                                                 lambda_1[0][0]                   \n",
            "                                                                 lambda_2[0][0]                   \n",
            "                                                                 lambda_3[0][0]                   \n",
            "                                                                 lambda_4[0][0]                   \n",
            "                                                                 lambda_5[0][0]                   \n",
            "                                                                 lambda_6[0][0]                   \n",
            "                                                                 lambda_7[0][0]                   \n",
            "                                                                 lambda_8[0][0]                   \n",
            "                                                                 lambda_9[0][0]                   \n",
            "                                                                 lambda_10[0][0]                  \n",
            "                                                                 lambda_11[0][0]                  \n",
            "                                                                 lambda_12[0][0]                  \n",
            "                                                                 lambda_13[0][0]                  \n",
            "                                                                 lambda_14[0][0]                  \n",
            "                                                                 lambda_15[0][0]                  \n",
            "                                                                 lambda_16[0][0]                  \n",
            "                                                                 lambda_17[0][0]                  \n",
            "                                                                 lambda_18[0][0]                  \n",
            "                                                                 lambda_19[0][0]                  \n",
            "                                                                 lambda_20[0][0]                  \n",
            "                                                                 lambda_21[0][0]                  \n",
            "                                                                 lambda_22[0][0]                  \n",
            "                                                                 lambda_23[0][0]                  \n",
            "                                                                 lambda_24[0][0]                  \n",
            "                                                                 lambda_25[0][0]                  \n",
            "                                                                 lambda_26[0][0]                  \n",
            "                                                                 lambda_27[0][0]                  \n",
            "                                                                 lambda_28[0][0]                  \n",
            "                                                                 lambda_29[0][0]                  \n",
            "                                                                 lambda_30[0][0]                  \n",
            "                                                                 lambda_31[0][0]                  \n",
            "                                                                 lambda_32[0][0]                  \n",
            "                                                                 lambda_33[0][0]                  \n",
            "                                                                 lambda_34[0][0]                  \n",
            "                                                                 lambda_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 1, 1, 2304)   0           patch_model[0][0]                \n",
            "                                                                 patch_model[1][0]                \n",
            "                                                                 patch_model[2][0]                \n",
            "                                                                 patch_model[3][0]                \n",
            "                                                                 patch_model[4][0]                \n",
            "                                                                 patch_model[5][0]                \n",
            "                                                                 patch_model[6][0]                \n",
            "                                                                 patch_model[7][0]                \n",
            "                                                                 patch_model[8][0]                \n",
            "                                                                 patch_model[9][0]                \n",
            "                                                                 patch_model[10][0]               \n",
            "                                                                 patch_model[11][0]               \n",
            "                                                                 patch_model[12][0]               \n",
            "                                                                 patch_model[13][0]               \n",
            "                                                                 patch_model[14][0]               \n",
            "                                                                 patch_model[15][0]               \n",
            "                                                                 patch_model[16][0]               \n",
            "                                                                 patch_model[17][0]               \n",
            "                                                                 patch_model[18][0]               \n",
            "                                                                 patch_model[19][0]               \n",
            "                                                                 patch_model[20][0]               \n",
            "                                                                 patch_model[21][0]               \n",
            "                                                                 patch_model[22][0]               \n",
            "                                                                 patch_model[23][0]               \n",
            "                                                                 patch_model[24][0]               \n",
            "                                                                 patch_model[25][0]               \n",
            "                                                                 patch_model[26][0]               \n",
            "                                                                 patch_model[27][0]               \n",
            "                                                                 patch_model[28][0]               \n",
            "                                                                 patch_model[29][0]               \n",
            "                                                                 patch_model[30][0]               \n",
            "                                                                 patch_model[31][0]               \n",
            "                                                                 patch_model[32][0]               \n",
            "                                                                 patch_model[33][0]               \n",
            "                                                                 patch_model[34][0]               \n",
            "                                                                 patch_model[35][0]               \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 2304)         0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1)            2305        flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 67,617\n",
            "Trainable params: 67,617\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyTiix-n_pgj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "outputId": "89c0c911-3595-4b56-d206-d55f0c8af9ec"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.losses import binary_crossentropy, MSE\n",
        "import glob\n",
        "import time\n",
        "import random\n",
        "import sys\n",
        "\n",
        "class WGAN():\n",
        "  def __init__(self, \n",
        "               img_size=128, \n",
        "               code_num = 2048,\n",
        "               batch_size = 16, \n",
        "               train_epochs = 100, \n",
        "               train_steps = 8, \n",
        "               checkpoint_epochs = 25, \n",
        "               image_epochs = 1, \n",
        "               start_epoch = 1,\n",
        "               optimizer = Adam(learning_rate = 1e-4),\n",
        "               n_critics = 8\n",
        "               ):\n",
        "    \n",
        "    self.batch_size = batch_size\n",
        "    self.train_epochs =  train_epochs\n",
        "    self.train_steps = train_steps\n",
        "    self.checkpoint_epochs = checkpoint_epochs\n",
        "    self.image_epochs = image_epochs\n",
        "    self.start_epoch = start_epoch\n",
        "    self.code_num = code_num\n",
        "    self.img_size = img_size\n",
        "    self.n_critics = n_critics\n",
        "    \n",
        "    self.gen_optimizer = optimizer\n",
        "    self.disc_optimizer = optimizer\n",
        "\n",
        "    g = Generator()\n",
        "    self.gen = g.model()\n",
        "    \n",
        "    d = Discriminator()\n",
        "    self.disc = d.model()\n",
        "\n",
        "    checkpoint_dir = \"drive/My Drive/PatchWGAN/checkpoint\"\n",
        "    checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "    checkpoint = tf.train.Checkpoint(gen_optimizer = self.gen_optimizer,\n",
        "                                     disc_optimizer = self.disc_optimizer,\n",
        "                                     gen = self.gen,\n",
        "                                     disc = self.disc,\n",
        "                                     )\n",
        "\n",
        "    self.manager = tf.train.CheckpointManager(checkpoint, directory=checkpoint_dir, max_to_keep=2)\n",
        "\n",
        "    train_image_path = 'drive/My Drive/samples/image'\n",
        "    \n",
        "    self.train_filenames = glob.glob(train_image_path + '/*.jpg') \n",
        "\n",
        "    checkpoint.restore(self.manager.latest_checkpoint)\n",
        "\n",
        "    self.g_history = []\n",
        "    self.d_history = []\n",
        "    # self.endec_history = []  \n",
        "\n",
        "  def preprocess_image(self, image):\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, [self.img_size, self.img_size] )\n",
        "    image = image/255  # normalize to [0,1] range\n",
        "    return tf.cast(image, tf.float32)\n",
        "\n",
        "  def load_and_preprocess_image(self, path):\n",
        "    image = tf.io.read_file(path)\n",
        "    return self.preprocess_image(image)\n",
        "\n",
        "  def dataset(self, paths, batch_size):\n",
        "    AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "    path_ds = tf.data.Dataset.from_tensor_slices(paths)\n",
        "    img_ds = path_ds.map(self.load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
        "    img_ds = img_ds.batch(batch_size)\n",
        "    return img_ds\n",
        "\n",
        "  def image_preparation(self, filenames, batch_size, steps):\n",
        "    img_batch = []\n",
        "    while 1:\n",
        "      random.shuffle(filenames)\n",
        "      for path in filenames:\n",
        "        img_batch.append(path)\n",
        "        if len(img_batch) == steps*batch_size:\n",
        "          imgs = self.dataset(img_batch, batch_size)\n",
        "          img_batch = []\n",
        "          yield imgs\n",
        "\n",
        "  def discriminator_loss(self, original_outputs, generated_outputs):\n",
        "    real_loss = binary_crossentropy(tf.ones_like(original_outputs), original_outputs)\n",
        "    generated_loss = binary_crossentropy(tf.zeros_like(generated_outputs), generated_outputs)\n",
        "    loss_d = tf.math.reduce_mean(real_loss + generated_loss)\n",
        "    return loss_d\n",
        "\n",
        "  def generator_loss(self, generated_outputs):\n",
        "    loss_g = tf.math.reduce_mean(binary_crossentropy(tf.ones_like(generated_outputs), generated_outputs))\n",
        "    return loss_g\n",
        "\n",
        "  def mse_loss(self, true, pred):\n",
        "    loss =  tf.math.reduce_mean(MSE(true, pred))\n",
        "    return loss\n",
        "\n",
        "  def wasserstein_loss(self, ori_outputs, gen_outputs):\n",
        "    d_loss = -tf.reduce_mean(ori_outputs) + tf.reduce_mean(gen_outputs)\n",
        "    g_loss = -tf.reduce_mean(gen_outputs)\n",
        "    return d_loss, g_loss\n",
        "  \n",
        "  def gan_train(self, imgs, n):\n",
        "    noise =tf.random.uniform([self.batch_size, self.code_num], minval=0, maxval=1, dtype=tf.dtypes.float32)\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      gen_imgs = self.gen(noise, training=True)\n",
        "\n",
        "      ori_outputs = self.disc(imgs, training=True)\n",
        "      gen_outputs = self.disc(gen_imgs, training=True)\n",
        "\n",
        "      # ori_outputs, ori_styles = self.disc(imgs, training=True)\n",
        "      # gen_outputs, gen_styles = self.disc(gen_imgs, training=True)\n",
        "      \n",
        "      # gen_loss = self.generator_loss(gen_outputs)      \n",
        "      # disc_loss = self.discriminator_loss(ori_outputs, gen_outputs)\n",
        "\n",
        "      # re_gen_imgs = self.gen(ori_styles, training=True)\n",
        "\n",
        "      # endec_loss = self.mse_loss(imgs, re_gen_imgs)\n",
        "      # self.endec_history.append(endec_loss)\n",
        "      \n",
        "      disc_loss, gen_loss = self.wasserstein_loss(ori_outputs, gen_outputs)\n",
        "      self.g_history.append(gen_loss)\n",
        "      self.d_history.append(disc_loss)\n",
        "\n",
        "      # endec_rate = 10*(0.98**n)\n",
        "      # g_loss = gen_loss + endec_loss * endec_rate\n",
        "      # d_loss = disc_loss + endec_loss * endec_rate\n",
        "\n",
        "      g_loss = gen_loss\n",
        "      d_loss = disc_loss\n",
        "\n",
        "    gradients_of_gen = gen_tape.gradient(g_loss, self.gen.trainable_variables)\n",
        "    self.gen_optimizer.apply_gradients(zip(gradients_of_gen, self.gen.trainable_variables))\n",
        "\n",
        "    gradients_of_disc = disc_tape.gradient(d_loss, self.disc.trainable_variables)    \n",
        "    self.disc_optimizer.apply_gradients(zip(gradients_of_disc, self.disc.trainable_variables))\n",
        "\n",
        "  def g_train(self, imgs):\n",
        "    noise =tf.random.uniform([self.batch_size, self.code_num], minval=0, maxval=1, dtype=tf.dtypes.float32)\n",
        "\n",
        "    with tf.GradientTape() as gen_tape:\n",
        "      gen_imgs = self.gen(noise, training=True)\n",
        "\n",
        "      ori_outputs = self.disc(imgs, training=False)\n",
        "      gen_outputs = self.disc(gen_imgs, training=False)\n",
        "\n",
        "      _, g_loss = self.wasserstein_loss(ori_outputs, gen_outputs)\n",
        "      self.g_temp.append(g_loss)\n",
        "\n",
        "    gradients_of_gen = gen_tape.gradient(g_loss, self.gen.trainable_variables)\n",
        "    self.gen_optimizer.apply_gradients(zip(gradients_of_gen, self.gen.trainable_variables))\n",
        "\n",
        "  def d_train(self, imgs):\n",
        "    noise =tf.random.uniform([self.batch_size, self.code_num], minval=0, maxval=1, dtype=tf.dtypes.float32)\n",
        "\n",
        "    with tf.GradientTape() as disc_tape:\n",
        "      gen_imgs = self.gen(noise, training=False)\n",
        "\n",
        "      ori_outputs = self.disc(imgs, training=True)\n",
        "      gen_outputs = self.disc(gen_imgs, training=True)\n",
        "      \n",
        "      d_loss, _ = self.wasserstein_loss(ori_outputs, gen_outputs)\n",
        "      self.d_temp.append(d_loss)\n",
        "\n",
        "    gradients_of_disc = disc_tape.gradient(d_loss, self.disc.trainable_variables)    \n",
        "    self.disc_optimizer.apply_gradients(zip(gradients_of_disc, self.disc.trainable_variables))\n",
        "\n",
        "  def visualise_batch(self, s_1, epoch):\n",
        "    gen_img = self.gen(s_1)  \n",
        "    gen_img = (np.array(gen_img*255, np.uint8))\n",
        "    fig, axes = plt.subplots(4, 6)\n",
        "    for idx, img in enumerate(gen_img):\n",
        "      p, q = idx//6, idx%6\n",
        "      axes[p, q].imshow(img)\n",
        "      axes[p, q].axis('off')\n",
        "    \n",
        "    save_name = 'drive/My Drive/PatchWGAN/generated_image/'+'image_at_epoch_{:04d}.png'\n",
        "    plt.savefig(save_name.format(epoch), dpi=200)\n",
        "    # plt.pause(0.1)\n",
        "    plt.close('all')\n",
        "\n",
        "  def loss_vis(self):\n",
        "    plt.plot(self.g_history, 'b', self.d_history, 'r')\n",
        "    plt.title('blue: g  red: d')\n",
        "    plt.savefig('drive/My Drive/PatchWGAN/loss/gan_loss.png')\n",
        "    plt.close('all')\n",
        "    # plt.plot(self.endec_history)\n",
        "    # plt.savefig('drive/My Drive/PatchWGAN/loss/endec_loss.png')\n",
        "    # plt.close('all')\n",
        "\n",
        "  def update_loss_history(self):\n",
        "    self.d_history.append(sum(self.d_temp)/len(self.d_temp))\n",
        "    self.g_history.append(sum(self.g_temp)/len(self.g_temp))\n",
        "    self.d_temp = []\n",
        "    self.g_temp = []\n",
        "\n",
        "  def __call__(self):\n",
        "    sample_noise =tf.random.uniform([24, self.code_num], minval=0, maxval=1, dtype=tf.dtypes.float32)\n",
        "    image_loader = self.image_preparation(self.train_filenames, self.batch_size, self.train_steps)\n",
        "    self.d_temp = []\n",
        "    self.g_temp = []\n",
        "    [w.assign(tf.clip_by_value(w, -0.01, 0.01)) for w in self.disc.variables]\n",
        "\n",
        "    for epoch in range(self.start_epoch, self.train_epochs+1):\n",
        "      print ('\\nepochs {}'.format(epoch))\n",
        "      imgs_ds = next(image_loader)\n",
        "\n",
        "      for steps, imgs in enumerate(imgs_ds):\n",
        "        print(\"\\r\" + 'steps{}'.format(steps+1), end=\"\")\n",
        "        sys.stdout.flush()\n",
        "\n",
        "        self.d_train(imgs)\n",
        "        [w.assign(tf.clip_by_value(w, -0.01, 0.01)) for w in self.disc.variables]\n",
        "\n",
        "        if steps % self.n_critics == 0:\n",
        "          self.g_train(imgs)\n",
        "        \n",
        "      self.update_loss_history()\n",
        "                               \n",
        "      if epoch % self.image_epochs == 0:\n",
        "        self.visualise_batch(sample_noise, epoch)\n",
        "        self.loss_vis()\n",
        "\n",
        "      if epoch % self.checkpoint_epochs == 0:\n",
        "        print ('\\nSaving checkpoint at epoch{}\\n\\n'.format(epoch))\n",
        "        self.manager.save()\n",
        "      \n",
        "if __name__ == '__main__':\n",
        "  a = WGAN(img_size = 32,\n",
        "           code_num = 8,\n",
        "           batch_size = 256,\n",
        "           train_epochs = 10000, \n",
        "           train_steps = 8, \n",
        "           checkpoint_epochs = 100, \n",
        "           image_epochs = 10, \n",
        "           start_epoch = 1,\n",
        "           optimizer = RMSprop(lr=5E-5),\n",
        "           n_critics = 2\n",
        "           )\n",
        "  a()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epochs 1\n",
            "steps8\n",
            "epochs 2\n",
            "steps2"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-1945e64e34ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    249\u001b[0m            \u001b[0mn_critics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m            )\n\u001b[0;32m--> 251\u001b[0;31m   \u001b[0ma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-1945e64e34ba>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_by_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-1945e64e34ba>\u001b[0m in \u001b[0;36md_train\u001b[0;34m(self, imgs)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_temp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0mgradients_of_disc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisc_tape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisc_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients_of_disc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1071\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1073\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    160\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_grad.py\u001b[0m in \u001b[0;36m_Conv2DGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    594\u001b[0m           \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m           \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m           data_format=data_format),\n\u001b[0m\u001b[1;32m    597\u001b[0m       gen_nn_ops.conv2d_backprop_filter(\n\u001b[1;32m    598\u001b[0m           \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d_backprop_input\u001b[0;34m(input_sizes, filter, out_backprop, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1250\u001b[0m         \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"use_cudnn_on_gpu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"padding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m         \u001b[0;34m\"explicit_paddings\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data_format\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1252\u001b[0;31m         \"dilations\", dilations)\n\u001b[0m\u001b[1;32m   1253\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}